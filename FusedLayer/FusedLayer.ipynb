{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "from typing import Any\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, **kwargs: Any) -> None:\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels, eps=0.001)\n",
    "        self.relu = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.conv(x)\n",
    "        # out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "class vgg16(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(vgg16, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            BasicConv2d(3, 64, kernel_size=3, padding=1),\n",
    "            BasicConv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            BasicConv2d(64, 128, kernel_size=3, padding=1),\n",
    "            BasicConv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            BasicConv2d(128, 256, kernel_size=3, padding=1),\n",
    "            BasicConv2d(256, 256, kernel_size=3, padding=1),\n",
    "            BasicConv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            BasicConv2d(256, 512, kernel_size=3, padding=1),\n",
    "            BasicConv2d(512, 512, kernel_size=3, padding=1),\n",
    "            BasicConv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            BasicConv2d(512, 512, kernel_size=3, padding=1),\n",
    "            BasicConv2d(512, 512, kernel_size=3, padding=1),\n",
    "            BasicConv2d(512, 512, kernel_size=3, padding=1),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layers = [*self.features]\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "        self.layers = [*self.features]\n",
    "        self.input_shape = 3, 224, 224\n",
    "        self.depth = len(self.features)\n",
    "        self.next = [*list(range(1, self.depth)), []]\n",
    "        self.output_shapes = [(1, 64, 224, 224), (1, 64, 224, 224), (1, 64, 112, 112), (1, 128, 112, 112),\n",
    "                              (1, 128, 112, 112), (1, 128, 56, 56), (1, 256, 56, 56), (1, 256, 56, 56),\n",
    "                              (1, 256, 56, 56), (1, 256, 28, 28), (1, 512, 28, 28), (1, 512, 28, 28), (1, 512, 28, 28),\n",
    "                              (1, 512, 14, 14), (1, 512, 14, 14), (1, 512, 14, 14), (1, 512, 14, 14), (1, 512, 7, 7)]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def forward_feature(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "    def forward_classifier(self, x):\n",
    "        return self.classifier(torch.flatten(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_layerConfigs(layers: list):\n",
    "    configs = []\n",
    "    for layer in layers:\n",
    "        if isinstance(layer, BasicConv2d):\n",
    "            conv = layer.conv\n",
    "            layer_config = {'type': 'basicConv', 'kernel_size': conv.kernel_size, 'stride': conv.stride,\n",
    "                            'padding': conv.padding}  # , 'bn_args': (bn.weight, bn.bias, False, bn.momentum, bn.eps)}\n",
    "        elif isinstance(layer, nn.Conv2d):\n",
    "            layer_config = {'type': 'basicConv', 'kernel_size': layer.kernel_size, 'stride': layer.stride,\n",
    "                            'padding': layer.padding}\n",
    "        elif isinstance(layer, nn.ReLU):\n",
    "            layer_config = {'type': 'relu', 'inplace': layer.inplace}\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            layer_config = {'type': 'maxpool', 'kernel_size': layer.kernel_size, 'stride': layer.stride,\n",
    "                            'padding': layer.padding, 'ceil_mode': layer.ceil_mode}\n",
    "        elif isinstance(layer, nn.Upsample):\n",
    "            layer_config = {'type': 'upsample', 'scale_factor': layer.scale_factor}\n",
    "        elif layer == 'concat':\n",
    "            layer_config = {'type': layer}\n",
    "        else:  # only given kinds of layers\n",
    "            layer_config = None\n",
    "            print('This type of layer is not supported yet')\n",
    "        configs.append(layer_config)\n",
    "\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_input(output_range: tuple, layer_config=None) -> tuple:\n",
    "    o_s, o_e = output_range\n",
    "    layer_type = layer_config['type']\n",
    "    if layer_type in ['relu', 'concat']:  # most activation layers\n",
    "        return output_range\n",
    "    elif layer_type == 'upsample':\n",
    "        scale_factor = layer_type['scale_factor']\n",
    "        return round(o_s / scale_factor), round(o_e / scale_factor)\n",
    "    elif layer_type in ('conv', 'basicConv', 'maxpool'):\n",
    "        kernel_size, stride, padding = layer_config['kernel_size'], layer_config['stride'], layer_config['padding']\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        if isinstance(stride, int):\n",
    "            stride = (stride, stride)\n",
    "        if padding != 0:\n",
    "            padding = padding[1]\n",
    "        return o_s * stride[1] - padding, (o_e - 1) * stride[1] + kernel_size[1] - padding\n",
    "        # return o_s * stride[1] - padding, o_e * stride[1] + kernel_size[1] - padding - 1\n",
    "    else:\n",
    "        print('Unknown layer type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ranges_backwards(layer_configs, output_shapes, last_output_range):\n",
    "    '''\n",
    "    given a layers chain, and the output range of the last layer, calculate the\n",
    "    :param layer_configs: the layer configuration of the chain layers\n",
    "    :param output_shapes: output shapes of the given layers\n",
    "    :param last_output_range: the output range of the last layer\n",
    "    :return: the input range of the first layer, and updated layer_configuration (and input range of intermediate layers)\n",
    "    '''\n",
    "    output_range = last_output_range\n",
    "    first_input_range = None\n",
    "    assert len(layer_configs) == len(output_shapes)\n",
    "    new_layer_configs = copy.deepcopy(layer_configs)\n",
    "    for l in range(len(layer_configs) - 1, -1, -1):  # consider there are just only conv and maxpool layers\n",
    "        layer_config = new_layer_configs[l]  # layer config of the current layer\n",
    "        # output_shape = output_shapes[l]\n",
    "        # H = output_shape[-1]\n",
    "        if l > 0:\n",
    "            H = output_shapes[l - 1][-1]\n",
    "        else:\n",
    "            H = 224  # model.input_shape\n",
    "        i_s, i_e = input_range = output_input(output_range, layer_config)  # [i_s, i_e)\n",
    "        if layer_config['padding'] == 0:\n",
    "            padding = (0, 0, 0, 0)\n",
    "        else:\n",
    "            if i_s < 0:\n",
    "                upper_padding = -i_s\n",
    "                i_s = 0\n",
    "            else:\n",
    "                upper_padding = 0\n",
    "            if i_e > H:\n",
    "                bottom_padding = i_e - H\n",
    "                i_e = H\n",
    "            else:\n",
    "                bottom_padding = 0\n",
    "            padding = (upper_padding, bottom_padding, *layer_config['padding'][-2:])\n",
    "            input_range = (i_s, i_e)\n",
    "        layer_config['padding'] = padding\n",
    "        if l == 0:\n",
    "            first_input_range = input_range\n",
    "        else:\n",
    "            output_range = input_range\n",
    "\n",
    "    return first_input_range, new_layer_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16()\n",
    "\n",
    "output_shapes =model.output_shapes  # 18 layers in feature extraction\n",
    "output_shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'type': 'basicConv',\n",
       "  'kernel_size': (3, 3),\n",
       "  'stride': (2, 2),\n",
       "  'padding': (1, 1)}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Conv2d(3, 64, bias=False, kernel_size=3, padding=1, stride=2)\n",
    "output_shapes = [(1, 64, 224, 224)]\n",
    "\n",
    "last_output_shape = output_shapes[-1]\n",
    "length = last_output_shape[-1]\n",
    "\n",
    "layers = [model]\n",
    "layer_configs = generate_layerConfigs(layers)\n",
    "\n",
    "print(layers)\n",
    "layer_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_output_shape = output_shapes[-1]\n",
    "length = last_output_shape[-1]\n",
    "\n",
    "layers = model.layers\n",
    "layer_configs = generate_layerConfigs(layers)\n",
    "\n",
    "# print(layers)\n",
    "layer_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output range: (0, 0) and input range: (0, 0)\n",
      "output range: (0, 1) and input range: (0, 2)\n",
      "output range: (0, 2) and input range: (0, 4)\n",
      "output range: (0, 3) and input range: (0, 6)\n",
      "output range: (0, 4) and input range: (0, 8)\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    range_test = (0, i)\n",
    "    input_range_test, _ = cal_ranges_backwards(layer_configs, output_shapes, range_test)\n",
    "    print(f'output range: {range_test} and input range: {input_range_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output range: (0, 4) and input range: (0, 218)\n",
      "output range: (3, 7) and input range: (6, 224)\n"
     ]
    }
   ],
   "source": [
    "range1 = (0, 4)\n",
    "range2 = (3, 7)\n",
    "input_range1, layer_configs1 = cal_ranges_backwards(layer_configs, output_shapes, range1)\n",
    "print(f'output range: {range1} and input range: {input_range1}')\n",
    "input_range2, layer_configs2 = cal_ranges_backwards(layer_configs, output_shapes, range2)\n",
    "print(f'output range: {range2} and input range: {input_range2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_input = torch.randn((1, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fused_layer(x, layers, layer_configs):\n",
    "    input = None\n",
    "    out = None\n",
    "    for l, layer in enumerate(layers):\n",
    "        if l == 0:\n",
    "            input = x\n",
    "        layer_config = layer_configs[l]\n",
    "        if isinstance(layer, BasicConv2d):\n",
    "            weight = layer.conv.weight\n",
    "            out = F.conv2d(F.pad(input, layer_config['padding']), weight, stride=layer_config['stride'])\n",
    "            # out = F.batch_norm(out, torch.zeros(out.shape[1]), torch.ones(out.shape[1]), *self.operator['bn_args'])\n",
    "            out = F.relu(out, inplace=True)\n",
    "        elif isinstance(layer, nn.MaxPool2d):\n",
    "            out = F.max_pool2d(F.pad(input, pad=layer_config['padding']), layer_config['kernel_size'],\n",
    "                               stride=layer_config['stride'], padding=0, ceil_mode=layer_config['ceil_mode'])\n",
    "        else:\n",
    "            out = None\n",
    "        input = out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption = time.time()\n",
    "\n",
    "output = forward_fused_layer(demo_input[..., input_range2[0]:input_range2[1]], layers, layer_configs2)\n",
    "\n",
    "consumption = time.time() - consumption\n",
    "\n",
    "print(f'It takes {consumption} seconds to compute {size}/7 output of vgg16')\n",
    "\n",
    "### check : forward(padded_input1 + padded_input1_input2) == forward(input1) + forward(input2) x\n",
    "\n",
    "# padded_input1 = F.pad(demo_input[..., input_range1[0]: input_range1[1]], layer_configs1[0]['padding'])\n",
    "# padded_input2 = F.pad(demo_input[..., input_range2[0]: input_range2[1]], layer_configs2[0]['padding'])\n",
    "# print(padded_input1.shape, padded_input2.shape)\n",
    "input1 = demo_input[..., input_range1[0]: input_range1[1]]\n",
    "input2 = demo_input[..., input_range2[0]: input_range2[1]]\n",
    "\n",
    "for lc in layer_configs1:\n",
    "    if lc['padding'][-1] != 0: lc['padding'] = (0, 0, 0, 0)\n",
    "for lc in layer_configs2:\n",
    "    if lc['padding'][-1] != 0: lc['padding'] = (0, 0, 0, 0)\n",
    "\n",
    "output1 = forward_fused_layer(input1, layers, layer_configs1)\n",
    "output2 = forward_fused_layer(input2, layers, layer_configs2)\n",
    "output_sum = output1 + output2\n",
    "\n",
    "input12 = input1 + input2\n",
    "output12 = forward_fused_layer(input12, layers, layer_configs1)\n",
    "\n",
    "### forward(padded_input1 + padded_input1_input2) != forward(input1) + forward(input2)\n",
    "\n",
    "\n",
    "print(output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coded_computation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
