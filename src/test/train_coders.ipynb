{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dir:  f:\\MyCourse(5 delayed 1)\\erasure code\\non-linear erasure code\\src\\test\n",
      "changed dir:  f:\\MyCourse(5 delayed 1)\\erasure code\\non-linear erasure code\\src\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"original dir: \", os.getcwd())\n",
    "\n",
    "new_path = \"../\"\n",
    "os.chdir(new_path)\n",
    "\n",
    "print(\"changed dir: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 2, R: 1, N: 3\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameter\n",
    "\n",
    "# N = K + R, N is the distributed device number\n",
    "K = 2\n",
    "R = 1\n",
    "N = K + R\n",
    "\n",
    "print(f\"K: {K}, R: {R}, N: {N}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from base_model.LeNet5 import LeNet5\n",
    "from dataset.splited_dataset import SplitedTrainDataset\n",
    "from dataset.image_dataset import ImageDataset\n",
    "from encoder.mlp_encoder import MLPEncoder\n",
    "from decoder.mlp_decoder import MLPDecoder\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare base model (already trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (conv_block1): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block2): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "base_model_path = \"base_model/LeNet5/MNIST/2023_11_28/model.pth\"\n",
    "\n",
    "model = LeNet5(input_dim=(1, 28, 28), num_classes=10)\n",
    "model.load_state_dict(torch.load(base_model_path))\n",
    "print(model)\n",
    "model_distributed = model.get_conv_segment()\n",
    "model_fc = model.get_fc_segment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Encoder and Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splited Train Dataset: split_num=2, data_num=60000, data_shape=(1, 28, 20)\n",
      "data shape: (1, 28, 20)\n"
     ]
    }
   ],
   "source": [
    "train_datasets = SplitedTrainDataset()\n",
    "train_datasets.load(f\"./data/MNIST/split/{K}/split_train_datasets.pt\")\n",
    "\n",
    "data_shape = train_datasets.data_shape\n",
    "\n",
    "print(train_datasets.describe())\n",
    "print(f\"data shape: {data_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.calculate_conv_output((1,28,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPEncoder(\n",
      "  (nn): Sequential(\n",
      "    (0): Linear(in_features=1120, out_features=1120, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1120, out_features=560, bias=True)\n",
      "  )\n",
      ")\n",
      "MLPDecoder(\n",
      "  (nn): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = MLPEncoder(num_in=K, num_out=R, in_dim=data_shape)\n",
    "decoder = MLPDecoder(num_in=N, num_out=K, in_dim=(16,4,4 // K))\n",
    "\n",
    "print(encoder)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_distributed.to(device)\n",
    "model_fc.to(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "model_distributed.eval()\n",
    "model_fc.eval()\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 938/938 [00:11<00:00, 84.65it/s, loss=0.529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.5289015769958496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 938/938 [00:11<00:00, 84.87it/s, loss=0.36] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.3596523106098175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 938/938 [00:10<00:00, 85.74it/s, loss=0.273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.27286091446876526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 938/938 [00:10<00:00, 85.64it/s, loss=0.223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.22265571355819702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 938/938 [00:10<00:00, 87.37it/s, loss=0.188] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.18844646215438843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 938/938 [00:10<00:00, 85.39it/s, loss=0.162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.16204270720481873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 938/938 [00:10<00:00, 87.26it/s, loss=0.141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.14146225154399872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 938/938 [00:10<00:00, 91.70it/s, loss=0.127] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.12700247764587402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 938/938 [00:09<00:00, 95.37it/s, loss=0.115]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.11510047316551208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 938/938 [00:09<00:00, 94.13it/s, loss=0.104] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.10435627400875092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_datasets, batch_size=64, shuffle=False)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_encoder = optim.SGD(encoder.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_decoder = optim.SGD(decoder.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "epoch_num = 4\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epoch_num}\")\n",
    "    for images_list, label in train_loader_tqdm:\n",
    "        images_list = [images.to(device) for images in images_list]\n",
    "        label = label.to(device)\n",
    "\n",
    "        # forward\n",
    "        imageDataset_list = [\n",
    "            ImageDataset(images) for images in images_list + encoder(images_list)\n",
    "        ]\n",
    "        output_list = []\n",
    "        for i in range(N):\n",
    "            imageDataset = imageDataset_list[i]\n",
    "            output = model_distributed(imageDataset.images)\n",
    "            output_list.append(output)\n",
    "        decoded_output_list = decoder(output_list)\n",
    "        output = torch.cat(decoded_output_list, dim=3)\n",
    "        output = output.view(output.size(0), -1)\n",
    "\n",
    "        loss = criterion(output, label.view(label.size(0), -1))\n",
    "\n",
    "        # backward\n",
    "        optimizer_encoder.zero_grad()\n",
    "        optimizer_decoder.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_encoder.step()\n",
    "        optimizer_decoder.step()\n",
    "\n",
    "        train_loader_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epoch_num}], Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\MyCourse(5 delayed 1)\\erasure code\\non-linear erasure code\\src\\test\\train_coders.ipynb 单元格 17\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/MyCourse%285%20delayed%201%29/erasure%20code/non-linear%20erasure%20code/src/test/train_coders.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/MyCourse%285%20delayed%201%29/erasure%20code/non-linear%20erasure%20code/src/test/train_coders.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y \u001b[39m=\u001b[39m [e \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m loss_list \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m l]\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/MyCourse%285%20delayed%201%29/erasure%20code/non-linear%20erasure%20code/src/test/train_coders.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m记录的loss数量: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(y)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/MyCourse%285%20delayed%201%29/erasure%20code/non-linear%20erasure%20code/src/test/train_coders.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m最后一个loss: \u001b[39m\u001b[39m{\u001b[39;00my[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss_list' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = [e for l in loss_list for e in l]\n",
    "print(f\"记录的loss数量: {len(y)}\")\n",
    "print(f\"最后一个loss: {y[-1]}\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "date = now.strftime(\"%Y_%m_%d\")\n",
    "\n",
    "encoder_path = (\n",
    "    f\"encoder/MLP/MNIST/{date}/\"\n",
    "    + f\"encoder-\"\n",
    "    + f\"task_MNIST-basemodel_LeNet5-\"\n",
    "    + f\"in_{encoder.num_in}-out_{encoder.num_out}.pth\"\n",
    ")\n",
    "dirpath = os.path.dirname(encoder_path)\n",
    "if not os.path.exists(dirpath):\n",
    "    os.makedirs(dirpath)\n",
    "torch.save(encoder.state_dict(), encoder_path)\n",
    "\n",
    "decoder_path = (\n",
    "    f\"decoder/MLP/MNIST/{date}/\"\n",
    "    + f\"decoder-\"\n",
    "    + f\"task_MNIST-basemodel_LeNet5-\"\n",
    "    + f\"in_{decoder.num_in}-out_{decoder.num_out}.pth\"\n",
    ")\n",
    "dirpath = os.path.dirname(decoder_path)\n",
    "if not os.path.exists(dirpath):\n",
    "    os.makedirs(dirpath)\n",
    "torch.save(decoder.state_dict(), decoder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_distributed 0: 100%|██████████| 938/938 [00:02<00:00, 431.98it/s]\n",
      "model_distributed 1: 100%|██████████| 938/938 [00:00<00:00, 1101.48it/s]\n",
      "model_distributed 2: 100%|██████████| 938/938 [00:00<00:00, 1082.28it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mf:\\MyCourse(5 delayed 1)\\erasure code\\non-linear erasure code\\src\\test\\train_coders.ipynb 单元格 21\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/MyCourse%285%20delayed%201%29/erasure%20code/non-linear%20erasure%20code/src/test/train_coders.ipynb#X35sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m data_size \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/MyCourse%285%20delayed%201%29/erasure%20code/non-linear%20erasure%20code/src/test/train_coders.ipynb#X35sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m labels \u001b[39m=\u001b[39m train_datasets\u001b[39m.\u001b[39mlabels\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/MyCourse%285%20delayed%201%29/erasure%20code/non-linear%20erasure%20code/src/test/train_coders.ipynb#X35sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(labels)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/MyCourse%285%20delayed%201%29/erasure%20code/non-linear%20erasure%20code/src/test/train_coders.ipynb#X35sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m total \u001b[39m=\u001b[39m data_size\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/MyCourse%285%20delayed%201%29/erasure%20code/non-linear%20erasure%20code/src/test/train_coders.ipynb#X35sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "# encoder.eval()\n",
    "# decoder.eval()\n",
    "\n",
    "# images_list = [images.to(device) for images in train_datasets.images_list]\n",
    "\n",
    "# imageDataset_list = [\n",
    "#     ImageDataset(images) for images in images_list + encoder(images_list)\n",
    "# ]\n",
    "\n",
    "# output_list = []\n",
    "\n",
    "# # inference on N devices\n",
    "# for i in range(N):\n",
    "#     imageDataset = imageDataset_list[i]\n",
    "\n",
    "#     test_loader = DataLoader(imageDataset, batch_size=64, shuffle=False)\n",
    "#     test_loader_tqdm = tqdm(test_loader, desc=f\"model_distributed {i}\")\n",
    "\n",
    "#     output = torch.tensor([]).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         for images in test_loader_tqdm:\n",
    "#             images = images.to(device)\n",
    "#             output = torch.cat((output, model_distributed(images)), dim=0)\n",
    "\n",
    "#     output_list.append(output)\n",
    "\n",
    "\n",
    "# def lose_something(output_list, lose_index=None):\n",
    "#     if lose_index is None or len(lose_index) == 0:\n",
    "#         return output_list\n",
    "\n",
    "#     losed_output_list = []\n",
    "\n",
    "#     for i in range(len(output_list)):\n",
    "\n",
    "#         if i in lose_index:\n",
    "\n",
    "#             losed_output_list.append(torch.zeros_like(output_list[i]))\n",
    "#         else:\n",
    "\n",
    "#             losed_output_list.append(output_list[i])\n",
    "#     return losed_output_list\n",
    "\n",
    "\n",
    "# losed_output_list = lose_something(output_list)\n",
    "# decoded_output_list = decoder(losed_output_list)\n",
    "\n",
    "# output = torch.cat(decoded_output_list, dim=3)\n",
    "# output = output.view(output.size(0), -1)\n",
    "# data_size = output.size(0)\n",
    "# labels = train_datasets.labels\n",
    "# labels = torch.tensor(labels).to(device)\n",
    "# total = data_size\n",
    "# correct = 0\n",
    "# for i in tqdm(range(data_size)):\n",
    "#     _, predicted = torch.max(model_fc(output[i]).data, 0)\n",
    "#     correct += (predicted == labels[i]).sum().item()\n",
    "\n",
    "# print(f\"Accuracy on the Test set: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset.splited_dataset.SplitedTestDataset at 0x1f6d8106290>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset.splited_dataset import SplitedTestDataset\n",
    "\n",
    "test_datasets = SplitedTestDataset()\n",
    "test_datasets.load(f\"./data/MNIST/split/{K}/split_test_datasets.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_distributed 0: 100%|██████████| 157/157 [00:00<00:00, 548.83it/s]\n",
      "model_distributed 1: 100%|██████████| 157/157 [00:00<00:00, 835.11it/s]\n",
      "model_distributed 2: 100%|██████████| 157/157 [00:00<00:00, 980.20it/s] \n",
      "100%|██████████| 10000/10000 [00:07<00:00, 1256.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the Test set: 99.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "\n",
    "images_list = [images.to(device) for images in test_datasets.images_list]\n",
    "\n",
    "imageDataset_list = [\n",
    "    ImageDataset(images) for images in images_list + encoder(images_list)\n",
    "]\n",
    "\n",
    "output_list = []\n",
    "\n",
    "# inference on N devices\n",
    "for i in range(N):\n",
    "    imageDataset = imageDataset_list[i]\n",
    "\n",
    "    test_loader = DataLoader(imageDataset, batch_size=64, shuffle=False)\n",
    "    test_loader_tqdm = tqdm(test_loader, desc=f\"model_distributed {i}\")\n",
    "\n",
    "    output = torch.tensor([]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader_tqdm:\n",
    "            images = images.to(device)\n",
    "            output = torch.cat((output, model_distributed(images)), dim=0)\n",
    "\n",
    "    output_list.append(output)\n",
    "\n",
    "\n",
    "def lose_something(output_list, lose_index = None):\n",
    "    if lose_index is None or len(lose_index) == 0:\n",
    "        return output_list\n",
    "\n",
    "    losed_output_list = []\n",
    "\n",
    "    for i in range(len(output_list)):\n",
    "\n",
    "        if i in lose_index:\n",
    "\n",
    "            losed_output_list.append(torch.zeros_like(output_list[i]))\n",
    "        else:\n",
    "\n",
    "            losed_output_list.append(output_list[i])\n",
    "    return losed_output_list\n",
    "\n",
    "\n",
    "losed_output_list = lose_something(output_list)\n",
    "decoded_output_list = decoder(losed_output_list)\n",
    "\n",
    "output = torch.cat(decoded_output_list, dim=3)\n",
    "output = output.view(output.size(0), -1)\n",
    "data_size = output.size(0)\n",
    "labels = test_datasets.labels\n",
    "labels = torch.tensor(labels).to(device)\n",
    "total = data_size\n",
    "correct = 0\n",
    "for i in tqdm(range(data_size)):\n",
    "    _, predicted = torch.max(model_fc(output[i]).data, 0)\n",
    "    correct += (predicted == labels[i]).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the Test set: {100 * correct / total}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
