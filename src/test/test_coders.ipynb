{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dir:  f:\\MyCourse(5 delayed 1)\\erasure code\\non-linear erasure code\\src\\test\n",
      "changed dir:  f:\\MyCourse(5 delayed 1)\\erasure code\\non-linear erasure code\\src\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"original dir: \", os.getcwd())\n",
    "\n",
    "new_path = \"../\"\n",
    "os.chdir(new_path)\n",
    "\n",
    "print(\"changed dir: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 4, R: 1, N: 5\n",
      "TASK: MNIST, BASE_MODEL: LeNet5, DATE: 2023_12_01\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameter\n",
    "\n",
    "# N = K + R, N is the distributed device number\n",
    "K = 4\n",
    "R = 1\n",
    "N = K + R\n",
    "\n",
    "TASK = \"MNIST\"\n",
    "BASE_MODEL = \"LeNet5\"\n",
    "DATE = \"2023_12_01\"\n",
    "\n",
    "print(f\"K: {K}, R: {R}, N: {N}\")\n",
    "print(f\"TASK: {TASK}, BASE_MODEL: {BASE_MODEL}, DATE: {DATE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import os\n",
    "from typing import Any, List, Tuple, Dict, Optional\n",
    "\n",
    "from base_model.LeNet5 import LeNet5\n",
    "from dataset.splited_dataset import SplitedTestDataset\n",
    "from dataset.image_dataset import ImageDataset\n",
    "from encoder.mlp_encoder import MLPEncoder\n",
    "from decoder.mlp_decoder import MLPDecoder\n",
    "from util.split_data import split_data\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded successfully\n",
      "Sequential(\n",
      "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=256, out_features=120, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Sequential(\n",
      "    (0): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "base_model_path = \"base_model/LeNet5/MNIST/2023_11_28/model.pth\"\n",
    "\n",
    "model = LeNet5(input_dim=(1, 28, 28), num_classes=10)\n",
    "model.load_state_dict(torch.load(base_model_path))\n",
    "print(\"model loaded successfully\")\n",
    "\n",
    "model_distributed = model.get_conv_segment()\n",
    "model_fc = model.get_fc_segment().eval()\n",
    "\n",
    "model_distributed.to(device)\n",
    "model_fc.to(device)\n",
    "\n",
    "model_distributed.eval()\n",
    "model_fc.eval()\n",
    "\n",
    "print(model_distributed)\n",
    "print(model_fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splited Test Dataset: split_num=4, data_num=10000, data_shape=(1, 28, 16)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "test_datasets = SplitedTestDataset()\n",
    "test_datasets.load(f\"./data/MNIST/split/{K}/split_test_datasets.pt\")\n",
    "data_shape = test_datasets.data_shape\n",
    "data_num = test_datasets.data_num\n",
    "split_num = test_datasets.split_num\n",
    "print(test_datasets.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path = f\"encoder/MLP/MNIST/{DATE}/encoder-task_{TASK}-basemodel_{BASE_MODEL}-in_{K}-out_{R}.pth\"\n",
    "\n",
    "\n",
    "encoder = MLPEncoder(num_in=K, num_out=R, in_dim=tuple(data_shape))\n",
    "\n",
    "encoder.load_state_dict(torch.load(encoder_path))\n",
    "\n",
    "encoder.to(device)\n",
    "encoder.eval()\n",
    "images_list = [images.to(device) for images in test_datasets.images_list]\n",
    "\n",
    "imageDataset_list = [\n",
    "    ImageDataset(images) for images in images_list + encoder(images_list)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ditributed inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_distributed 0: 100%|██████████| 157/157 [00:00<00:00, 359.68it/s]\n",
      "model_distributed 1: 100%|██████████| 157/157 [00:00<00:00, 1375.61it/s]\n",
      "model_distributed 2: 100%|██████████| 157/157 [00:00<00:00, 1193.52it/s]\n",
      "model_distributed 3: 100%|██████████| 157/157 [00:00<00:00, 1084.41it/s]\n",
      "model_distributed 4: 100%|██████████| 157/157 [00:00<00:00, 1181.85it/s]\n"
     ]
    }
   ],
   "source": [
    "output_list = []\n",
    "\n",
    "# inference on N devices\n",
    "for i in range(N):\n",
    "    imageDataset = imageDataset_list[i]\n",
    "\n",
    "    test_loader = DataLoader(imageDataset, batch_size=64, shuffle=False)\n",
    "    test_loader_tqdm = tqdm(test_loader, desc=f\"model_distributed {i}\")\n",
    "\n",
    "    output = torch.tensor([]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader_tqdm:\n",
    "            images = images.to(device)\n",
    "            output = torch.cat((output, model_distributed(images)), dim=0)\n",
    "\n",
    "    output_list.append(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lose_something(\n",
    "    output_list: List[torch.Tensor], lose_index: Optional[Tuple[int]] = None\n",
    ") -> List[torch.Tensor]:\n",
    "    if lose_index is None or len(lose_index) == 0:\n",
    "        return output_list\n",
    "\n",
    "    losed_output_list = []\n",
    "\n",
    "    for i in range(len(output_list)):\n",
    "\n",
    "        if i in lose_index:\n",
    "\n",
    "            losed_output_list.append(torch.zeros_like(output_list[i]))\n",
    "        else:\n",
    "\n",
    "            losed_output_list.append(output_list[i])\n",
    "    return losed_output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_path = f\"decoder/MLP/MNIST/{DATE}/decoder-task_{TASK}-basemodel_{BASE_MODEL}-in_{N}-out_{K}.pth\"\n",
    "decoder = MLPDecoder(num_in=N, num_out=K, in_dim=tuple(output_list[0][0].size()))\n",
    "decoder.load_state_dict(torch.load(decoder_path))\n",
    "decoder.to(device)\n",
    "decoder.eval()\n",
    "losed_output_list = lose_something(output_list)\n",
    "decoded_output_list = decoder(losed_output_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:07<00:00, 1353.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the Test set: 9.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output = torch.cat(decoded_output_list, dim=3)\n",
    "output = output.view(output.size(0), -1)\n",
    "data_size = output.size(0)\n",
    "labels = test_datasets.labels\n",
    "labels = torch.tensor(labels).to(device)\n",
    "total = data_size\n",
    "correct = 0\n",
    "for i in tqdm(range(data_size)):\n",
    "    _, predicted = torch.max(model_fc(output[i]).data, 0)\n",
    "    correct += (predicted == labels[i]).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the Test set: {100 * correct / total}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
