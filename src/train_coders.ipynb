{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 2, R: 1, N: 3\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameter\n",
    "\n",
    "# N = K + R, N is the distributed device number\n",
    "K = 2\n",
    "R = 1\n",
    "N = K + R\n",
    "\n",
    "print(f\"K: {K}, R: {R}, N: {N}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from base_model.LeNet5 import LeNet5\n",
    "from dataset.splited_dataset import SplitedTrainDataset\n",
    "from dataset.image_dataset import ImageDataset\n",
    "from encoder.mlp_encoder import MLPEncoder\n",
    "from decoder.mlp_decoder import MLPDecoder\n",
    "from util.util import cal_output_size\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare base model (already trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (conv_block1): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_block2): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "base_model_path = \"base_model/LeNet5/MNIST/2023_11_28/model.pth\"\n",
    "\n",
    "model = LeNet5(input_dim=(1, 28, 28), num_classes=10)\n",
    "model.load_state_dict(torch.load(base_model_path))\n",
    "print(model)\n",
    "model_distributed = model.get_conv_segment()\n",
    "model_fc = model.get_fc_segment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Encoder and Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splited Train Dataset: split_num=2, data_num=60000, data_shape=(1, 28, 20)\n",
      "Origin data shape: torch.Size([1, 28, 20])\n"
     ]
    }
   ],
   "source": [
    "train_datasets = SplitedTrainDataset()\n",
    "train_datasets.load(f\"./data/MNIST/split/{K}/split_train_datasets.pt\")\n",
    "\n",
    "data_shape = train_datasets.data_shape\n",
    "\n",
    "print(train_datasets.describe())\n",
    "print(f\"data shape: {data_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPEncoder(\n",
      "  (nn): Sequential(\n",
      "    (0): Linear(in_features=1120, out_features=1120, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1120, out_features=560, bias=True)\n",
      "  )\n",
      ")\n",
      "MLPDecoder(\n",
      "  (nn): Sequential(\n",
      "    (0): Linear(in_features=384, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoder = MLPEncoder(num_in=K, num_out=R, in_dim=data_shape)\n",
    "output_size = cal_output_size(model_distributed, data_shape)\n",
    "decoder = MLPDecoder(num_in=N, num_out=K, in_dim=output_size)\n",
    "\n",
    "print(encoder)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder = MLPEncoder(\n",
    "#     input_dim=img_size,\n",
    "#     hidden_dims=[128, 64, 32],\n",
    "#     output_dim=32,\n",
    "#     activation=nn.ReLU(),\n",
    "#     dropout=0.5,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_distributed.to(device)\n",
    "model_fc.to(device)\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "model_distributed.eval()\n",
    "model_fc.eval()\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 938/938 [00:18<00:00, 51.05it/s, loss=0.598]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.597885012626648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 938/938 [00:16<00:00, 55.67it/s, loss=0.394]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.3939012885093689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 938/938 [00:16<00:00, 55.86it/s, loss=0.301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.30054810643196106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 938/938 [00:15<00:00, 60.97it/s, loss=0.245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.24453651905059814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 938/938 [00:10<00:00, 89.10it/s, loss=0.205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.20505504310131073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 938/938 [00:10<00:00, 88.39it/s, loss=0.178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.1780446171760559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 938/938 [00:10<00:00, 88.57it/s, loss=0.157]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.157220721244812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 938/938 [00:10<00:00, 90.56it/s, loss=0.141] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.14113657176494598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 938/938 [00:10<00:00, 89.28it/s, loss=0.128] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.1283937394618988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 938/938 [00:10<00:00, 86.81it/s, loss=0.118] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.11830160021781921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_datasets, batch_size=64, shuffle=False)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer_encoder = optim.SGD(encoder.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_decoder = optim.SGD(decoder.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "epoch_num = 10\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epoch_num}\")\n",
    "    for images_list, label in train_loader_tqdm:\n",
    "        images_list = [images.to(device) for images in images_list]\n",
    "        label = label.to(device)\n",
    "\n",
    "        # forward\n",
    "        imageDataset_list = [\n",
    "            ImageDataset(images) for images in images_list + encoder(images_list)\n",
    "        ]\n",
    "        output_list = []\n",
    "        for i in range(N):\n",
    "            imageDataset = imageDataset_list[i]\n",
    "            output = model_distributed(imageDataset.images)\n",
    "            output_list.append(output)\n",
    "        decoded_output_list = decoder(output_list)\n",
    "        output = torch.cat(decoded_output_list, dim=3)\n",
    "        output = output.view(output.size(0), -1)\n",
    "\n",
    "        loss = criterion(output, label.view(label.size(0), -1))\n",
    "\n",
    "        # backward\n",
    "        optimizer_encoder.zero_grad()\n",
    "        optimizer_decoder.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_encoder.step()\n",
    "        optimizer_decoder.step()\n",
    "\n",
    "        train_loader_tqdm.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epoch_num}], Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save encoder and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "date = now.strftime(\"%Y_%m_%d\")\n",
    "\n",
    "encoder_path = (\n",
    "    f\"encoder/MLP/MNIST/{date}/\"\n",
    "    + f\"encoder-\"\n",
    "    + f\"task_MNIST-basemodel_LeNet5-\"\n",
    "    + f\"in_{encoder.num_in}-out_{encoder.num_out}.pth\"\n",
    ")\n",
    "dirpath = os.path.dirname(encoder_path)\n",
    "if not os.path.exists(dirpath):\n",
    "    os.makedirs(dirpath)\n",
    "torch.save(encoder.state_dict(), encoder_path)\n",
    "\n",
    "decoder_path = (\n",
    "    f\"decoder/MLP/MNIST/{date}/\"\n",
    "    + f\"decoder-\"\n",
    "    + f\"task_MNIST-basemodel_LeNet5-\"\n",
    "    + f\"in_{decoder.num_in}-out_{decoder.num_out}.pth\"\n",
    ")\n",
    "dirpath = os.path.dirname(decoder_path)\n",
    "if not os.path.exists(dirpath):\n",
    "    os.makedirs(dirpath)\n",
    "torch.save(decoder.state_dict(), decoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 2])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(len(output_list))[:9]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
