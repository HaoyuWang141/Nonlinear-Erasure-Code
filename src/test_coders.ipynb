{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 2, R: 1, N: 3\n"
     ]
    }
   ],
   "source": [
    "# hyper-parameter\n",
    "\n",
    "# N = K + R, N is the distributed device number\n",
    "K = 2\n",
    "R = 1\n",
    "N = K + R\n",
    "\n",
    "print(f\"K: {K}, R: {R}, N: {N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from base_models.LeNet5 import LeNet5\n",
    "from util.dataset import PartitionedDataset, ImageDataset\n",
    "from encoder.mlp_encoder import MLPEncoder\n",
    "from decoder.mlp_decoder import MLPDecoder\n",
    "from data_processing.data_partition import data_partition\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded successfully\n",
      "model is on device: cuda:0\n",
      "model_distributed: device: cuda:0, mode: eval\n",
      "model_fc: device: cuda:0, mode: eval\n"
     ]
    }
   ],
   "source": [
    "base_model_path = \"base_models/LeNet5/MNIST/2023_11_28/model.pth\"\n",
    "\n",
    "model = LeNet5(input_dim=(1, 28, 28), num_classes=10)\n",
    "model.load_state_dict(torch.load(base_model_path))\n",
    "print(\"model loaded successfully\")\n",
    "\n",
    "model.to(device)\n",
    "print(f\"model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "\n",
    "model_distributed = model.get_conv_segment().eval()\n",
    "print(\n",
    "    f\"model_distributed: device: {next(model_distributed.parameters()).device}, mode: {'training' if model_distributed.training is True else 'eval'}\"\n",
    ")\n",
    "\n",
    "model_fc = model.get_fc_segment().eval()\n",
    "print(\n",
    "    f\"model_fc: device: {next(model_fc.parameters()).device}, mode: {'training' if model_fc.training is True else 'eval'}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    "# )\n",
    "\n",
    "# dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "# print(f\"Test dataset: {len(dataset)}\")\n",
    "# print(\"image size: \", dataset[0][0].size())\n",
    "# data_partition(\n",
    "#     model.get_conv_segment(),\n",
    "#     dataset,\n",
    "#     K,\n",
    "#     f\"./data/MNIST/partition/{K}/partitioned_test_datasets.pt\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of dataset: <class 'util.dataset.PartitionedDataset'>\n",
      "test_datasets num: 2, which shold be equal to K = 2\n",
      "constructure: ([images, images, ...], conv_segment_labels, labels)\n",
      "datasize: 10000\n",
      "image size: torch.Size([1, 28, 20])\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "test_datasets = torch.load(f\"data/MNIST/partition/{K}/partitioned_test_datasets.pt\")\n",
    "\n",
    "datasets_num = len(test_datasets[0][0])\n",
    "data_size = len(test_datasets)\n",
    "img_size = test_datasets[0][0][0].size()\n",
    "\n",
    "print(f\"type of dataset: {type(test_datasets)}\")\n",
    "print(f\"test_datasets num: {datasets_num}, which shold be equal to K = {K}\")\n",
    "print(f\"constructure: ([images, images, ...], conv_segment_labels, labels)\")\n",
    "print(f\"datasize: {data_size}\")\n",
    "print(f\"image size: {img_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_path = \"encoder/MLP/MNIST/2023_11_29/model.pth\"\n",
    "\n",
    "encoder = MLPEncoder(num_in=K, num_out=R, in_dim=tuple(img_size))\n",
    "encoder.load_state_dict(torch.load(encoder_path))\n",
    "encoder.to(device)\n",
    "\n",
    "images_list = [[] for _ in range(datasets_num)]\n",
    "for images, _, labels in test_datasets:\n",
    "    for i in range(datasets_num):\n",
    "        images_list[i].append(images[i])\n",
    "\n",
    "images_list = [torch.stack(images).to(device) for images in images_list]\n",
    "encoded_images_list = encoder(images_list)\n",
    "images_list = images_list + encoded_images_list\n",
    "\n",
    "imageDataset_list = [ImageDataset(images) for images in images_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ditributed inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_distributed 0: 100%|██████████| 157/157 [00:00<00:00, 451.04it/s]\n",
      "model_distributed 1: 100%|██████████| 157/157 [00:00<00:00, 616.08it/s]\n",
      "model_distributed 2: 100%|██████████| 157/157 [00:00<00:00, 625.50it/s]\n"
     ]
    }
   ],
   "source": [
    "output_list = []\n",
    "\n",
    "# inference on N devices\n",
    "for i in range(N):\n",
    "    imageDataset = imageDataset_list[i]\n",
    "\n",
    "    test_loader = DataLoader(imageDataset, batch_size=64, shuffle=False)\n",
    "    test_loader_tqdm = tqdm(test_loader, desc=f\"model_distributed {i}\")\n",
    "\n",
    "    output = torch.tensor([]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader_tqdm:\n",
    "            images = images.to(device)\n",
    "            output = torch.cat((output, model_distributed(images)), dim=0)\n",
    "\n",
    "    output_list.append(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_path = \"decoder/MLP/MNIST/2023_11_29/model.pth\"\n",
    "\n",
    "decoder = MLPDecoder(num_in=N, num_out=K, in_dim=tuple(output_list[0][0].size()))\n",
    "decoder.load_state_dict(torch.load(decoder_path))\n",
    "decoder.to(device)\n",
    "\n",
    "losed_output_list = [output_list[0], output_list[1], output_list[2]]\n",
    "# losed_output_list = [torch.zeros_like(output_list[0]), output_list[1], output_list[2]]\n",
    "\n",
    "decoded_output_list = decoder(losed_output_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:13<00:00, 762.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the Test set: 98.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output = torch.cat(decoded_output_list, dim=3)\n",
    "output = output.view(output.size(0), -1)\n",
    "\n",
    "data_size = output.size(0)\n",
    "\n",
    "labels = test_datasets.labels\n",
    "labels = torch.tensor(labels).to(device)\n",
    "\n",
    "total = data_size\n",
    "correct = 0\n",
    "for i in tqdm(range(data_size)):\n",
    "    _, predicted = torch.max(model_fc(output[i]).data, 0)\n",
    "    correct += (predicted == labels[i]).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the Test set: {100 * correct / total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lose_something(output_list, lose_index):\n",
    "    losed_output_list = []\n",
    "    for i in range(len(output_list)):\n",
    "        if i in lose_index:\n",
    "            losed_output_list.append(torch.zeros_like(output_list[i]))\n",
    "        else:\n",
    "            losed_output_list.append(output_list[i])\n",
    "    return losed_output_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
