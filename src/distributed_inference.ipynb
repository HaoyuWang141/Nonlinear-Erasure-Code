{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from base_models.LeNet5 import LeNet5\n",
    "from util.dataset import PartitionedDataset, ImageDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "filepath = \"base_models/LeNet5/MNIST/2023_11_28/model.pth\"\n",
    "\n",
    "model = LeNet5(input_dim=(1, 28, 28), num_classes=10)\n",
    "model.load_state_dict(torch.load(filepath))\n",
    "print(\"model loaded successfully\")\n",
    "\n",
    "model.to(device)\n",
    "print(f\"model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "model_distributed = model.get_conv_segment().eval()\n",
    "print(\n",
    "    f\"model_distributed: device: {next(model_distributed.parameters()).device}, mode: {'training' if model_distributed.training is True else 'eval'}\"\n",
    ")\n",
    "\n",
    "model_fc = model.get_fc_segment().eval()\n",
    "print(\n",
    "    f\"model_fc: device: {next(model_fc.parameters()).device}, mode: {'training' if model_fc.training is True else 'eval'}\"\n",
    ")\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "# load data\n",
    "test_datasets = torch.load(\"data/MNIST/partition/4/partitioned_test_datasets.pt\")\n",
    "\n",
    "datasets_num = len(test_datasets[0][0])\n",
    "data_size = len(test_datasets)\n",
    "img_size = test_datasets[0][0][0].size()\n",
    "\n",
    "print(f\"type of dataset: {type(test_datasets)}\")\n",
    "print(f\"test_datasets num: {datasets_num}, which shold be equal to K = {K}\")\n",
    "print(f\"constructure: ([images, images, ...], labels)\")\n",
    "print(f\"datasize: len(images) = len(labels) = {data_size}\")\n",
    "print(f\"image size: {img_size}\")\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "images_list = [[] for _ in range(datasets_num)]\n",
    "for img_list, label in test_datasets:\n",
    "    for i in range(datasets_num):\n",
    "        images_list[i].append(img_list[i])\n",
    "\n",
    "images_list = [torch.stack(images).to(device) for images in images_list]\n",
    "imageDataset_list = [ImageDataset(images) for images in images_list]\n",
    "\n",
    "output_list = []\n",
    "\n",
    "# inference on K devices\n",
    "for i in range(K):\n",
    "    imageDataset = imageDataset_list[i]\n",
    "\n",
    "    test_loader = DataLoader(imageDataset, batch_size=64, shuffle=False)\n",
    "    test_loader_tqdm = tqdm(test_loader, desc=f\"model_distributed {i}\")\n",
    "\n",
    "    output = torch.tensor([]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for img in test_loader_tqdm:\n",
    "            img = img.to(device)\n",
    "            output = torch.cat((output, model_distributed(img)), dim=0)\n",
    "\n",
    "    output_list.append(output)\n",
    "\n",
    "output = torch.cat(output_list, dim=3)\n",
    "output = output.view(output.size(0), -1)\n",
    "\n",
    "print(\"-\" * 20)\n",
    "\n",
    "data_size = output.size(0)\n",
    "\n",
    "labels = test_datasets.labels\n",
    "labels = torch.tensor(labels).to(device)\n",
    "\n",
    "total = data_size\n",
    "correct = 0\n",
    "for i in tqdm(range(data_size)):\n",
    "    _, predicted = torch.max(model_fc(output[i]).data, 0)\n",
    "    correct += (predicted == labels[i]).sum().item()\n",
    "\n",
    "print(f\"Accuracy on the Test set: {100 * correct / total}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
